# API Management
[[{20_qa.api_management,api_management.101,standards.api_management,use_case.crm,use_case.erp,security.aaa,use_case.payments,use_case.monetization,standards,security.privacy,use_case.b2b]]
## OpenAPI Spec 3.x <!-- { --> 
<https://swagger.io/specification/>
* language-agnostic RESTful APIs interface definition for computers and humans.
* can also be used as documentation.
* External Resources:
  * Collection of OpenAPI Tools: <https://github.com/OpenAPITools>
    * OpenAPI-diff:
      <https://github.com/quen2404/openapi-diff>
  * OpenAPI topics @ github:
    * <https://github.com/topics/openapi>
    * ...
  * Ex OpenAPi Definition:
  ```
   | openapi: '3.0.3'
   |
   | info:
   |   title: 'MyRESTService'
   |   description: MyRESTService API Document
   |   version: '0.0.1'
   |
   | servers: [ { url: https://www.mycompany.com/ } ]
   |
   | paths:
   |   '/api/v1/module1/service1':
   |     put:
   |       summary: ...
   |       description: >
   |         This is a multi-line markup description
   |          * bullet1
   |          * bullet2
   |       tags: [ MyModule1, Service1, ... ]   ← Orthogonal topics
   |
   |       requestBody:
   |         $ref: '#/components/requestBodies/entity01'
   |       parameters:
   |         - name: SecuritySchemes
   |           in  : header       ← :=  header ← HEAD / GET / PUT / POST
   |                                  | query  ←        GET / PUT / POST
   |                                  | body   ←              PUT / POST
   |           description: |
   |             Set Access Token
   |             Format: "Bearer"+[space]+[jwt]
   |           schema:
   |             $ref: "#/components/schemas/entity01"
   |           required: true
   |
   |         - name: queryParam1
   |           in  : query
   |           required: true
   |           schema:
   |             type: string    ← boolean | number | ...
   |                               { type: string, enum: [asc, desc] }
   |         - name: ...
   |
   |       responses:
   |         '200': { description: 'OK' }
   |         '400': { description: 'KO' }
   |
   |   '/api/v1/module1/service1':
   |     get:
   |       summary: ...
   |       ...
   |       responses:
   |         '200':
   |           description: 'OK'
   |           content:
   |             application/json:
   |               schema:
   |                 $ref: '#/components/schemas/entity01'
   |         ...
   |
   | components:
   |   schemas:
   |     entity01:
   |       type: object
   |       properties:
   |         blNo           : { type: string }
   |         senderCompanyId: { type: string }
   |         version        : { type: number }
   |
   |   requestBodies:
   |     entity01:
   |       content:
   |         "application/json":
   |           schema:
   |             $ref: '#/components/schemas/entity01'
   ```

### OpenAPI Tools:
* A collection of Editors, Linters, Parsers, Code Generators, Documentation, Testing 
  <https://github.com/apisyouwonthate/openapi.tools>
  * Auto Generators: Tools that will take your code and turn it into an OpenAPI Specification document
  * Converters: 
  * Data Validators:
  * Description Validators: 
  * Documentation: 
  * DSL: 
  * Gateways: 
  * GUI Editors: 
  * Learning: 
  * Miscellaneous: 
  * Mock Servers: 
  * Monitoring: Monitoring tools let you know what is going on in your API.
  * Parsers:
  * SDK Generators: 
  * Security: By poking around your OpenAPI description, some tools can look out for attack vectors you might not have noticed.
  * Server Implementations: 
  * Testing: Quickly execute API requests and validate responses on the fly. 


<!-- } -->

## WSO2 API Manager:
* Number 1 Open Source API Management Platform.
* full lifecycle API management platform for building, integrating, 
  securing, and exposing an enterprise's digital services as managed 
  APIs in cloud, on-premises, and hybrid architectures. Fast-track your 
  API strategy with all the capabilities needed by API designers, 
  product managers, operations, and consumers.

# How to Write API Tests (in 7 Easy Steps)  [[{]]

* <https://nordicapis.com/how-to-write-api-tests-in-7-easy-steps/>
1. Understand the Scope of the API
   * understand what the API does and what its responsibilities are.
   * What is the purpose of this API?
   * What kind of data does this API handle, and what are the data models used for?
   * What are the entry points to this API (endpoints/queries/tasks it accepts)?
   * What is their structure?
2. Understand the User Flows
   Try and understand how users use these applications and what API calls
   are being triggered by their usage.
3. Write API Tests
   At this point you should be all set to start creating API tests.
   Ideally, useful tests written in this step should have several traits:
   * Atomic: Each test should be self-contained.
   * Portable: Any data, configurations, and especially URLs should be passed
     as parameters to ensure portability between environments.
   * Repeatable: You should be able to re-run tests frequently.
4. Write Negative Tests and Edge Case Tests
5. Execute Tests against Dev and Stage environments
6. Connect Tests to CI/CD Pipeline
7. **Run Tests to Monitor Production Environments**
    One of the benefits of API tests is that you can easily run them
   in multiple environments. Specifically, you can run your tests
   periodically on your production environment to ensure it functions as
   expected. This can also help you collect performance data about your
   API to see degradations or changes in performance in real-time.
[[}]]


[[{api_management,standards,arch.async,PM.TODO]]
# Open Data Protocol
* <https://www.odata.org/>
* ISO/IEC approved, OASIS standard.
* It defines   set of best practices for building and consuming
  RESTful APIs to focus on business logic without worrying
  about different approaches to define request/response headers,
  status codes, HTTP methods, URL conventions, media types,
  payload formats, query options, etc.
* OData provides guidance for:
  · tracking changes
  · defining functions/actions for reusable procedures
  · sending asynchronous/batch requests.                           [async]
* OData RESTful APIs are easy to consume.
  - OData metadata, a machine-readable description of the
    data model of the APIs, enables the creation of powerful
    generic client proxies and tools.
* OData Tools include:
  - Visual Studio Code for OData Extension:
    - adds rich support for the OData query language
  - XOData
    - generic online OData API/Service visualizer and explorer.
      It assists in rapid prototyping, verification, testing,
      and documentation of OData APIs. With XOData Chrome App
      it's also possible to explore OData Services deployed
      locally or on private networks.
[[}]]

[[{arch.async,standards.api_management,api_management.101,20_qa,PM.TODO]]
# asyncapi.org/ #[asyncapi_summary]
<https://www.asyncapi.org/>
* Low level standard (vs OpenAPI high-level/business oriented)
  to architect future event-driven architectures.
* Open source tools to easily build and maintain your event-driven
  architecture. All powered by the AsyncAPI specification, the industry
  standard for defining asynchronous APIs.
* Compatible with OpenAPI Spec, allowing to re-use schema definitions.
* See comparative with OpenAPI and CloudEvents at:
  <https://www.asyncapi.com/blog/async_standards_compare>

## Extracted from ebay anouncement to adopt AsyncAPI:
<https://www.infoq.com/news/2021/05/ebay-adopts-asyncapi/>
    One of the critical AsyncAPI features that eBay's team has found
  particularly useful is   clean separation between channels,
  operations, and servers.
  · A channel represents an event stream
  · An operation describes a publish or subscribe process.
  · A server facilitates the message transfer (i.e., the message bus).
  This separation allows a complete representation of producers, consumers,
  and message schemas, resulting in a standardized model of a
  message-driven ecosystem.
[[}]]

[[{PM.low_code,api_management,20_qa.testing,PM.TODO]]
# Mirage: Fast Prototyping
* <https://miragejs.com>
* Mirage JS is an API mocking library that lets you build, test and
  share a complete working JavaScript application without having to
  rely on any backend services.

# WireMock
* HTTP-based simulator to mock APIs for fast, robust and comprehensive testing.
* Fix the problem of testing APIs that do NOT yet exists or is imcomplete.
* test edge cases/failure modes that real API won't reliably produce.
* It can reduce build time from hours to minutes.
[[}]]

[[{api_management.apigee,PM.TODO]]
# APIgee: x-Cloud API Mng
- The Cross-Cloud API Management Platform
  https://cloud.google.com/apigee/
[[}]]


# Postman/Newman SUMMARY:  [[{]]
  =======================

┌───────────────────────────────────────────────────────────────────────────────────────────────┐
│ WARN:                                                                                         │
│   Postman is NOT suitable for proper testing (as of 2022─08─25).                              │
│ It works "OK" when testing isolated request─response("unit tests") , but complexity grows     │
│ exponentially when trying to create chain of expected requests─responses ("functional tests"),│
│ requiring lot of custom─and─non─standard code "juggling" with variables                       │
│ to be able to keep state. It neither allows to check "stuff" outside the API, like            │
│ state of DDBBs, pending messages in queues, ... making integration tests impossible.          │
│                                                                                               │
│   Also, due to the async nature of Javascript, simple things like "wait for N seconds" to let │
│ previous request be processed in background become really tricky. An simple "sleep 10" in     │
│ shell script needs a search in stackoverflow to search for custom patch code in Postman/Newman│
└───────────────────────────────────────────────────────────────────────────────────────────────┘

REF: http://www.postmanlabs.com/postman-collection/tutorial-concepts.html
     https://github.com/postmanlabs/postman-collection/blob/develop/types/index.d.ts

                                     ┌────────────┐   ┌───────────┐
                   ┌─────────────────┤ Collection ├───>Information│
                   │                 └─────┬──────┘   └───────────┘
                   │                       │
           ┌───────v───┐                ┌──v───┐
           │ ItemGroup │        ┌───────┤ Item ├──────────┐
           └─┬────────┬┘        │       └───┬──┘          │
             │        │         │           │             │
    ┌────────v──┐ ┌───v──┐ ┌────v────┐ ┌────v──────┐  ┌───v────┐
    │ ItemGroup │ │ Item │ │ Request │ │ Responses │  │ Events │
    └───────────┘ └──────┘ └─────────┘ └───────────┘  └────────┘

    "ItemGroup" is referred to as "Folder" in UIs/newman output.


# pre-request tests and (post-response) test examples:
  REF: https://learning.postman.com/docs/writing-scripts/script-references/test-examples/

  pm.test("XXXX", () => {                                 <- create test spec inside Pre-request|Tests scripts.
                                                              returns back pm, allowing for chainable calls.

    setTimeout(() => {
      pm.expect(pm.response.code).to.equal(200)           ;
      done();                                             <- (optional), useful to test async.functions.
    }, 1500);

    pm.test.index()                                       <- Get total-number-of-tests executed

    pm.expect(pm.environment.name).to.eql("DEV");         <- Check active Postman environment

    pm.response.to.have.status(200);                      <- alt 1: Chai Assertion Library BDD syntax
    pm.expect(pm.response.code).to.eql(200);              <- alt 2: programatic response.
    pm.expect(pm.response.code).to.be.oneOf([201,202]);   <- Check range of codes
    pm.response.to.have.status("Created");

    pm.response.to.have.header("Content-Type");           TESTING RESPONSE HEADERS:
    pm.expect(
     pm.response.headers.get('Content-Type')
    ).to.eql('application/json');

    pm.expect(pm.cookies.has('JSESSIONID')).to.be.true;   TEST RESPONSE COOKIE
    pm.expect(pm.cookies.get('isLoggedIn')).to.eql('1');


    pm.expect(pm.response.responseTime).to.be.below(200); TESTING RESPONSE TIMES

                                                    // parsing response.
    const responseJson = pm.response.json();        // <- Alt 1: Parse as JSON
    pm.expect(jsonData.errors).to.be.empty;         // { ..., "errors" : [], ...}
    pm.expect(jsonData.areas).to.include("goods");  // { ... "areas": [ ... "goods", ... ], ...}
    pm.expect(responseJson.type).to.eql('vip');
    pm.expect(responseJson.name).to.be.a('string');
    pm.expect(responseJson.name).to.eql(
                pm.environment.get("NAME"));           <- Use ENV.VAR
    pm.expect(responseJson.id).to.have.lengthOf(1);
    pm.expect(responseJson.age).to.eql(23);

  //const responseJson = xml2Json(pm.response.text()); <- Alt.2: Parse as XML

  //const parse=require('csv─parse/lib/sync');         <- Alt.3: Parse as CSV.
  //const responseJson = parse(pm.response.text());

    const $ = cheerio.load(pm.response.text());     // <- Alt.4: Parse HTML
    console.log($.html());

    pm.expect(pm.response.text())                   // <- Alt.5.1: Non-parseable response.
       .to.include("customer_id");
    pm.response.to.have.body("whole-body-text");    // <- Alt.5.2: Non-parseable response.

    pm.expect(jsonData).to.be.an("object");            TESTING RESPONSE SCHEMA. ALT 1.
    pm.expect(jsonData.name).to.be.a("string");        {
    pm.expect(jsonData.age).to.be.a("number");           "name": "Jane",
    pm.expect(jsonData.hobbies).to.be.an("array");       "age": 29,
    pm.expect(jsonData.website).to.be.undefined;         "hobbies": [ "..", ],
    pm.expect(jsonData.email).to.be.null;                "email": null
                                                       }

     const schema = {                                  TESTING RESPONSE SCHEMA. ALT 2.
      "items": {                                       (Using Tiny Validator V4 tv4)
         "type": "boolean"
      }
     };
     const data1 = [true, false];
     pm.expect(tv4.validate(data1, schema)).to.be.true;


     const schema = {                                      TESTING RESPONSE SCHEMA. ALT 3.
       "properties": {                                     Ajv JSON schema validator
         "alpha": {
           "type": "boolean"
         }
       }
     };
     pm.response.to.have.jsonSchema(schema);

                                                           FILTER/SEARCH INTO OBJECT SCHEMA:
    const notificationSettings = jsonData.settings.find    <- find == "filter"
        (m => m.type === "type1");                          |{
    pm.expect(notificationSettings)                         | "settings": [
      .to.be.an("object", "error ....");                    |  { "type": "type1", "set1":["val1","val2"] },
    pm.expect(notificationSettings.set1).to.include("val2");|  { ... },
    pm.expect(notificationSettings.set1)                    |   ],
      .to.have.members(["val1", "val2"]);                   |   ...
                                                            |}

    const expected = { "key1":true, "error":[] }                     EXPECT OBJECT "DEEP" IN RESPONSE
    pm.expect(pm.response.json()).                                   { "key1": true, "key2":..., "error": [] }
     to.deep.include(expected);                                      will match

    // .deep causes all .equal|.include|.members|.keys|.property
    // assertions that follow in the chain to use deep/loose
    // equality (vs strict '===' equality).
    // '.eql' also compares loosely but doesn't apply to             [[{doc_has.comparative]]
    // assertions following in the chain, while .eql does.           [[}]]
  });

   pm.expect({a: 1, b: 2}).to.have.all.keys('a', 'b');      <- .all is the default in not indicated.
   pm.expect({a: 1, b: 2}).to.have.any.keys('a', 'b');
   pm.expect({a: 1, b: 2}).to.not.have.any.keys('c', 'd');
   pm.expect({a: 1}).to.have.property('a');
   pm.expect({a: 1, b: 2}).to.be.an('object')
     .that.has.all.keys('a', 'b');

# TROUBLESHOOTING COMMON TEST ERRORS:
  console  .log() // .info() .warn() .error()
  pm.collectionVariables.get("varname1")

# POSTMAN SANDBOX API (pm.* providing access to request/response data and vars): [[{]]
  https://learning.postman.com/docs/writing-scripts/script-references/postman-sandbox-api-reference/

## VISIBILITY SCOPES FOR VARIABLES:
  pm.variables           : Variables NOT persisted across new requests or collections.
  pm.iterationData       : Data
  pm.collectionVariables : Environment  <- Variables of this collection (not shared with others in same project)
  pm.environment         : Collection   <- Variables shared among (same project) and different collections
  pm.globals             : Global
  Note: same var.names can be defined in different scope. "Closest" one takes precendence.

  pm.variables.toObject()            <-  Return all vars+values in SCOPE
  pm.variables.has(varName:String)
  pm.variables.get(varName:String)
  pm.variables.set(varName:String, varValue:*)
  pm.variables.unset(variableName:String)
  pm.variables.clear()               <- Clear all vars
  pm.variables.replaceIn("... {{$varName}}"); // <- {{$varName}} resolves to
    └────┬───┘                                     current value of var.
    alternatively: .iterationData | .collectionVariables | .environment | .globals

  SCOPE SPECIFIC METHODS
  ======================
  pm.environment        .name:String   <- Current ENV.NAME.
  pm.iterationData      .toJSON()

## REQUEST/RESPONSE API:
 ┌ REQUEST ───────────────────────┐
 │ pm.request.url:Url             │
 │ pm.request.headers:HeaderList  │
 │ pm.request.method:String       │
 │ pm.request.body:RequestBody    <- RequestBody is IMMUTABLE
 │ pm.request.headers.add   ({key:'headerN',value: 'valueN'})
 │ pm.request.headers.upsert({key:'headerN',value: 'valueN'})
 │ pm.request.headers.remove(name)│
 ├ RESPONSE ──────────────────────┤
 │ pm.response.code:Number        │
 │ pm.response.status:String      │
 │ pm.response.headers:HeaderList │
 │ pm.response.responseTime:Number│
 │ pm.response.responseSize:Number│
 │ pm.response.text() → String    │
 │ pm.response.json() → Object    │
 ├ info ──────────────────────────┤
 │ pm.info.eventName := prerequest| test
 │ pm.info.iteration:Number       │
 │ pm.info.iterationCount:Number  │
 │ pm.info.requestName:String     │
 │ pm.info.requestId:String   <- unique GUID
 ├ pm.cookies ────────────────────┤
 │ pm.cookies.has(sKey)           │
 │ pm.cookies.get(sKey)           │
 │ pm.cookies.toObject() → Object │
 │ pm.cookies.jar() → Object      <- specify domain for access to request cookies.
 │ To enable programmatic access: │
 │ 1) add the cookie URL to the allowlist.
 │                                │
 │ jar.set("httpbin.org",         │     <- URL:String
 │         "session-id", "abc123",│     <- Set cookie using name+value.
 │         └───────────────────┴─········ Alt: use PostmanCookie|compatible object
 │                                │        { name, value, isHTTPOnly }
 │         (e, cookie) => {       │     <- Callback
 │           if (e) { throw e };  │
 │           console.log(`Cookie:${cookie}`);
 │         }                      │
 │ );                             │
 │ jar.get(URL, cookieName, callback (error, value))   <- Get cookie from cookie-jar
 │ jar.getAll(URL         , callback (error, cookies)) <- Get all the cookies
 │ jar.unset(URL, token, callback(error))              <- Remove cookie
 │ jar.clear(URL:String, callback (error)) → Object    <- Clear all cookies from jar
 └────────────────────────────────┘

## SENDING (ASYNC) REQUESTS FROM PRE-REQUEST|TEST SCRIPTs.
  =======================================================
  const GET_REQUEST01  = 'https://.../post',    <- Alt 1: Simplified GET      REQUEST
  const POST_REQUEST01 = {                      <- Alt 2: detailed   POST/PUT REQUEST
    url: 'https://postman-echo.com/post',
    method: 'POST',
    header: {
      'Content-Type': 'application/json',
      'X-Foo': 'bar'
    },
    body: {
      mode: 'raw',
      raw: JSON.stringify({ key: '...' })      <- Converting JSON to "RAW STRING"
    }
  };
  pm.sendRequest(POST_REQUEST01,               <- TRIGGERS ASYNC REQUEST
    (err, resp) => { if (err) { ... }
    pm.test('...', () => {
      pm.expect(e).to.equal(null);
      pm.expect(resp).to.have.property('code', 200);
      pm.expect(resp).to.have.property('status', 'OK');
    });
  });

  ┌─ COMPLEX WORKFLOWS ─────────────────────────────────────────────────┐
  │ ─ When you running a collection Postman will run the requests in:   │
  │   ─  DEFAULT ORDER or                                               │
  │   ─  ORDER SPECIFIED WHEN SETTING UP THE TEST.                      │
  │                                                                     │
  │   THIS ORDER CAN BE OVERRIDING USING pm.setNextRequest              │
  │                                                                     │
  │ PATTERN: use 'NEXT' enviroment-scoped state var as "state machine"  │
  │ for non-trivial workflows. e.g:                                     │
  │                                                                     │
  │ request 1 "pushes" NEXT pointing to itself (pm.info.requestId):     │
  │   pm.environment.set('NEXT', pm.info.requestId)                     │
  │                                                                     │
  │ request 2 "pulls" NEXT  and calls back request 1:                   │
  │   postman.setNextRequest(pm.environment.get('NEXT'));               │
  └─────────────────────────────────────────────────────────────────────┘
    WARN: setNextRequest has NO effect when running isolated requests.
          only running collections or Newman.

## SCRIPTING POSTMAN VISUALIZATIONS
  ================================
    pm.visualizer.set(      <- set template to for response data in 'Postman Visualizer'
      `<p>{{res.info}}</p>`,       <- HTML template
      { res: pm.response.json() }, <- (opt): JSON accessible inside template string
      options:Object               <- (opt): Options for Handlebars.compile()
    )

    pm.getData( (error, data) => { <- Building Response data into Visualizations
      var value = data.res.info;      (tpl string)
    });

## USING EXTERNAL LIBRARIES
  require(moduleName:String)

  └ SANDBOX BUILT-IN LIBRARY MODULES:
    ajv       : JSON schema validator
    atob      : ASCII  to Base64 lib.
    btoa      : Base64 to ASCII lib.
    chai      :
    cheerio   : markup-to-tree parsing + traversing/manipulating API
    crypto-js :
    csv-parse/lib/sync:
    lodash    : ("latest" with v3.10.1 preloaded)
    moment    : Deprecated/legacy JS 'date' library
    postman-collection:
    tv4       :
    uuid      :
    xml2js    :
  └ NODEJS MODULES:
    path , assert  , buffer  , util  , url  ,
    querystring , string-decoder  , stream  , timers  , events
    punycode (Convert complex codings to/from ASCII).
[[}]]

# Running Collections on the command-line with newman: [[{]]
  # REF: https://learning.postman.com/docs/running-collections/using-newman-cli/newman-options/
  npx newman run \                 <- Official docker images supported:
    --env-var "host=${IP}" \          docker run -t postman/newman run ...
    --env-var "port=15000" \
    --color off \
    --disable-unicode  \
    --insecure \
    projectcollection.json

  # BASIC OPTIONS:
  # ==============
  # -e, --environment $file_or_URL
  # -d, --iteration-data $file
  # -g, --globals $file
  # -n, --iteration-count $number
  # --working-dir $path         work path to use while reading files with relative paths. Def: CWD
  # --no-insecure-file-read     Prevents reading of files situated outside work-dir.
  # --export-environment [path] file_path output for final environment variables file before completing a run
  # --export-globals [path]     file_path output for final global variables file before completing a run
  # --export-collection [path]  file_path output for final collection file before completing a run
  #
  # REQUEST OPTIONS
  # ===============
  # --delay-request   $millisec_delay_between_request
  # --timeout         $millisecs_for_entire_collection_execution
  # --timeout-request $millisecs
  # --timeout-script  $millisecs_timeout_for_scripts
  #
  # MISCELLANEOUS OPTIONS
  # =====================
  # --bail                      Stops runner when a test-case fails.
  # --silent                    Turn off terminal output.
  # --color off                 (auto*|on|off)
  # --disable-unicode
  # --insecure                  Turn off strict SSL.
  # --suppress-exit-code        Continue running tests even after a failure AND exit with code=0
  # --ignore-redirects          Turn off automatic following of 3XX responses.
  # --verbose                   Show detailed information of collection run and each request sent.
  # --cookie-jar [path]         Specify the file path for a JSON Cookie Jar. Uses tough-cookie to deserialize the file.
  # --export-cookie-jar $path]  path to-file where Newman will output final cookie jar file before completing a run.
  # --global-var "GLOBAL_VAR_NAME=SOME_VALUE"
  # --env-var "ENV_VAR_NAME=SOME_VALUE"

## USING NEWMAN AS A NODE.JS LIBRARY: <- This allows to integrate Postman test with other types of tests.
  var newman = require('newman');
  const RUN_OPTIONS = {
    collection: require('./sample-collection.json'),
    reporters: 'cli'
  }
  const RUN_CALLBACK = (err) => {
      if (err) { throw err; }
      console.log('collection run complete!');
  }
  newman.run(RUN_OPTIONS, RUN_CALLBACK);

## UPLOADING FILES (relative location to collection).

  ┌─ file─upload.postman_collection.json ─────────
  │   $ newman run file-upload.postman_collection.json
  │ {
  │   "variables": [],
  │   "info": {
  │     "name": "file-upload",
  │     "_postman_id": "9dbfcf22-fdf4-f328-e440-95dbd8e4cfbb",
  │     "schema": "https://schema.getpostman.com/json/collection/v2.0.0/collection.json"
  │   },
  │   "item": [
  │     {
  │       "name": "FORM DATA UPLOAD",
  │       "request": {
  │         "description": "Upload file as FORM-DATA field using a 'POST' request."
  │         "url": "https://postman-echo.com/post",
  │         "method": "POST",
  │         "header": [],
  │         "body": {
  │           "mode": "formdata",
  │           "formdata": [
  │             { "key": "file",
  │               "type": "file",
  │               "enabled": true,
  │               "src": "sample-file.txt" }
  │           ]
  │         },
  │       },
  │       "event": [
  │         {
  │           "listen": "test",
  │           "script": {
  │             "type": "text/javascript",
  │             "exec": [
  │               "var response = JSON.parse(responseBody).files[\"sample-file.txt\"];",
  │               "",
  │               "tests[\"Status code is 200\"] = responseCode.code === 200;",
  │               "tests[\"File was uploaded correctly\"] = /^data:application\\/octet-stream;base64/.test(response);",
  │               ""
  │             ]
  │           }
  │         }
  │       ]
  │       "response": []
  │     }
  │   ]
  │ }
  └───────────────────────────────────────────────

## USING NEWMAN CUSTOM (COLLECTION RUN) REPORTERS

 - Use case example:
   - logging out response body when a request (or its tests) fail.


 - custom reporter: Node.js module with name 'newman-reporter-$name' or @myorg/newman-reporter-$name

   /- index.js ---------------------
   | function (emitter, reporterOptions, collectionRunOptions) {
   |   // emitter              : event emitter triggering newmanrunevents (https://github.com/postmanlabs/newman#newmanrunevents)
   |   // reporterOptions      : object of the reporter specific options.
   |   // collectionRunOptions :
   |   // https://github.com/postmanlabs/newman#newmanrunoptions-object--callback-function--run-eventemitter
   | };

   2) Publish reporter using npm publish,


   3) Use it:
   $ npm install newman-reporter-teamcity

   cli:
   $ newman run collection.json -r teamcity --reporter-myreporter-$OPTION_NAME $OPTION_VALUE  # (option is optional)

   programatically:
   var newman = require('newman');
   newman.run({
      collection: 'collection.json',
      reporters: 'myreporter',
      reporter: {
        myreporter: {
          'option-name': 'option-value'
        }
      }
   }, function (err, summary) {
     ...
   });
[[}]]

# Code generator library  [[{]]
  - https://learning.postman.com/docs/developer/code-generators/
  - https://github.com/postmanlabs/postman-code-generators
  Utility to auto-generate client-code for API collections in any supported lang:
  Currently:  csharp ,shell curl/libcurl/wget/httpie ,dart ,golang ,http ,java ,
              js/nodejs, objective-c, ocaml, php, powershell, python, Rlang, ruby
  (https://github.com/postmanlabs/postman-code-generators/tree/develop/codegens)

  - PRESETUP
    └ Alt 1) npm
      $ npm install --save-dev postman-code-generators (NodeJS+npm preinstalled)
        ...
        added 78 packages, and audited 79 packages in 1m

    └ Alt 2) git + npm
      $ git clone https://github.com/postmanlabs/postman-code-generators.git
      $ npm install;             <- install all dependencies in production mode.
      $ npm run deepinstall dev; <- install dev dependencies also for all codegens run:

  PROGRAMATIC USSAGE:

  const TARGET_CLIENT_LAN = 'nodejs'
  const TARGET_CLIENT_VARIANT = 'request'
  const CODEGEN = require('postman-code-generators'),
  const SDK = require('postman-collection'),
  const REQUEST01 = new SDK.Request('https://www.google.com'),

  console.log(CODEGEN.getLanguageList()); <- Get supported lang. list

  CODEGEN.getOptions(                 <- (optional) find supported config
     TARGET_CLIENT_LAN,               options for target (language,variant)
     TARGET_CLIENT_VARIANT,
     (error, opts) => {... .log(opts);}
     } );

  const CONVERT_OPTIONS = {
          indentCount: 3,
          indentType: 'Space',
          trimRequestBody: true,
          followRedirect: true
        };

  CODEGEN.convert(
     TARGET_CLIENT_LAN,
     TARGET_CLIENT_VARIANT,
     REQUEST01, CONVERT_OPTIONS,
     (error, snippet) => {... .log(snippet);}
  });
[[}]]

# Collection SDK (CI/CD Pipelines): [[{]]
  http://www.postmanlabs.com/postman-collection/
  https://github.com/postmanlabs/postman-collection
   The Collection SDK provides an interface for working with
  the data structures defined by the Postman Collection Schema.
  creating/modifying collection elements, define request detail,
  variables, authentication, :..

  const         FS   = require('fs'),
        COLLECTION   = require('postman-collection').Collection;

  const STRING_INPUT = FS.readFileSync('collection01.json').toString() // <- read collection file as string
  const myCollection = new COLLECTION(JSON.parse(STRING_INPUT));       // <- parse to collection object

[[}]]


# TODO:
- Postman Utilities:
  - https://learning.postman.com/docs/developer/intro-api/
  - https://learning.postman.com/docs/developer/echo-api/
  - https://learning.postman.com/docs/developer/runtime-library/
  - https://learning.postman.com/docs/developer/collection-conversion/
    convert from a variety of API formats into Postman Collections.
    (Currently OpenAPI, Swagger, RAML, or GraphQL schema)


- https://github.com/AmadeusITGroup/Postman-Orchestrator 

- https://github.com/postmanlabs/newman/blob/develop/examples/find-unique-urls-in-run.js

## https://github.com/BBVA/apicheck
   APICheck focuses not only in the security testing and hacking use
   cases. The goal of the project is to become a complete toolset for
   DevSecOps cycles.
[[}]]

## API MANAGEMENT Comparative  [[{api_management]]
- APIARY: used for collaborative designing, documenting and governing
    API's helping to adopt API first approach with templates and best
    practices.
  - Out Platform is strongly integrated with our API guidelines, helping us
    to achieve consistency of all our API's.
  - Out Platform is strongly integrated with our API guidelines, helping us
  - speeds up and simplifies the development and testing phase by providing  [[qa.testing]]
    API mock services and automation of API testing.

- MASHERY: delivers key API management capabilities.
  - Features include:
    API creation, packaging, testing, and management of your API's and
    community of users.
- API SECURITY: provided via an embedded or optional on-premise API gateway.

- RUNSCOPE: continuous monitoring platform for all our API's
  - It monitors uptime, performance and validates the data.
  - tightly integrated with Slack and Opsgenie in order to alert and
    create incident if things are going wrong way.
  - Runscope can quickly detect any issues with our API's [[qa.SLA]]
[[}]]


# AmadeusITGroup/docu.me [[{]]
  https://github.com/AmadeusITGroup/docu.me 
* Documentation Portal Generator helps setting up clear,
  searchable, easy-to-customize documentation portal for APIs
  from your Swagger specifications.
[[}]]


# Appium browser/mobile functional testing [[{]]
http://appium.io/docs/en/about-appium/getting-started/?lang=es 
[[}]]

[[{api_management,PM.TODO]]
## Packaging APIs for consumers with Red Hat 3scale API Management
https://developers.redhat.com/blog/2021/03/02/packaging-apis-for-consumers-with-red-hat-3scale-api-management/
[[}]]


## KrakendD fastest API gateway:   [[{]]
* Stateless, immutability and performance architecture,
* 70000 request/sec on  commodity hardware.
* Much faster than Kong or Tyk
* Features include:
  - Monitoring (Logging and stats)
  - Security (SSL and security policies)
  - Trhottling (rate limiting, user quota)
  - Proxy (OAuth, Protocol Translation, Load Balancing)
  - QoS (Concurrent calls, circuit braker, Grained timeout)
  - Cache (Caching headers)
  - Aggregation (Merge sources)
  - Manipulation (Transform)
  - Filtering
  - Decoding (From JSON, XML, ...)


                     ··· /cart        cart.api.com server
                     ·
FE App ···> Krakend ···· /stock  warehouse.api.com server
                     ·
                     ··· /orders   finance.api.com server

### Krakend Shadow API Testing [[{PM.low_code,20_qa,PM.TODO]]
 https://www.krakend.io/blog/krakend-shadow-testing/?1627926585889
 Traffic mirroring: test your APIs automatically, without writing tests
 [[}]]
[[}]]


## POST (CREATE) vs PUT (Update / idempotent)
https://stackoverflow.com/questions/630453/what-is-the-difference-between-post-and-put-in-http
